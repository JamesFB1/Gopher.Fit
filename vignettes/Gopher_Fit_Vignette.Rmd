---
title: "Gopher.Fit Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Gopher_Fit_Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, echo = FALSE, message=FALSE}
library(Gopher.Fit)
library(tidyverse)
library(patchwork)
load("~/Gopher.Fit/data/tortoise.rda")
```

## Exploratory Data Analysis

The main goal of this package is to fit a Poisson GLMM to the Gopher Tortoise data set, and describe the relationship between increasing seroprevalance of upper respiratory tract infections in Gopher Tortoises on the number of shells found (i.e., the number of dead tortoises) after accounting for the area of each site. Before doing that it is important to analyze the data ourselves.   

The data set has 7 variables; Site, Year, Shells, Type, Area, Density, and Prev. The first row of the data is shown here:

```{r, echo = FALSE}
tortoise %>%
  head(n = 1L) %>%
  knitr::kable()
```

The response variable of our model is the Shells variable which measures the number of dead tortoises within each site. We want to study the relationship between this variable and both the Prev and Area variables. Before fitting the model we should explore this relationship further. 

```{r, echo = FALSE, fig.width= 7, fig.height=4}
tortoise$year = cut(tortoise$year, 
                    breaks = c(0, 2004.5, 2005.5, 2007), 
                    labels = c("2004", "2005", "2006"))

# colourblind friendly palette
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#550994", "#882255")

ggplot(data = tortoise, aes(x = Area, y = shells, color = Site, shape = year)) +
  geom_point() +
  theme_bw() + 
  theme(legend.position = "top") + 
  labs(title = "Area of Site vs. Number of Shells", 
       x = "Area of Site", 
       y = "Number of Shells") + 
  guides(shape = guide_legend(title = "Year")) +
  scale_color_manual(values = cbbPalette)

ggplot(data = tortoise, aes(x = prev, y = shells, color = Site, shape = year)) +
  geom_point() +
  theme_bw() + 
  theme(legend.position = "top") + 
  labs(title = "Seroprevalence vs. Number of Shells", 
       x = "Seroprevalence", 
       y = "Number of Shells") + 
  guides(shape = guide_legend(title = "Year")) +
  scale_color_manual(values = cbbPalette)
```

These plots show the relationship between these variables. We can see that both variables have a slight positive correlation with Shells, but Prev has more influence on Shells. One particular site that is particularly telling is the "CF" site. We can see the first two year have low seroprevalence and there are 0 Shells, and then in 2006 when seroprevalence increases to around 45, shells increases to 3. There are a few outliers.

These outliers can be explained by this table below. It shows that over 2003 there was an especially high level of Shells even with an average prevalence over the sites lower than the following years.

```{r, echo = FALSE}
shells_by_year = tortoise %>%
  group_by(year) %>%
  summarize("Total Shells" = sum(shells),
            "Average Prevalence" = mean(prev))

shells_by_year %>%
  knitr::kable()
```

This next table shows total shells across all years by site, as well as the average prevalence across the years. It shows that the highest number of shells belongs to the site with the highest average prevalence, and the lowest number of shells with the lowest average prevalence.

```{r, echo = FALSE}
shells_by_site = tortoise %>%
  group_by(Site) %>%
  summarize("Total Shells" = sum(shells),
            "Average Prevalence" = round(mean(prev), digits = 3)) %>%
  arrange(desc(`Total Shells`))

shells_by_site %>%
  knitr::kable()
```

## Data Processing

Before fitting the model, we clean up the dataset by adding an ID column and removing the type and density columns as we are not interested in these variables.

```{r}
tortoise_clean <- tortoise %>%
    rowid_to_column("ID") %>%  # add ID column
    select(-type, -density)    # delete type and density columns
```

## Bootstrap

After fitting the model using the run_model function, we will now use the function SE_CI from this package to find the standard errors and confidence intervals. This function implements a parametric bootstrap by simulating the random effects from $N(0, \sigma^2)$, since the random effects are assumed to be independent and identically distributed normal random variables with mean 0 and variance $\sigma^2$ $(Z_i \stackrel{iid}{\sim} N(0, \sigma^2)$.

Below, we implement function using the gopher tortoises data. The function returns a list of 3 tibbles. The tibbles contain the standard error, and upper and lower confidence interval estimates for $\beta_0$, $\beta_1$, and $\sigma^2$.

```{r}
# Estimating Standard Errors and Confidence Intervals
se_ci_estimates <- SE_CI(tortoise_clean)

```

Within the function, we first fit our model using the run_model function. For ease, we add the value of $\hat{\beta_1}x_{ij1}$ to the dataset.

Next, we wish to generate 1000 bootstrap samples. The SE_CI function will resample the values of the 10 random effects for each of the 3 years to obtain 1000 bootstrap samples of size 30. Since we have the estimates of the fixed effects from our initial fit of the model, we can compute $\eta_{ij}^* = \beta_0 + \beta_1x_{ij1} + log(x_{i2}) + z_i^*$ for $i=1, ..., 10$ and $j = 1,2,3$. Since $\mu_{ij} = e^{\eta_{ij}}$, we can compute $\mu_{ij}^*$ and simulate new $Y_{ij}^* \sim \text{Poisson}(\mu_{ij}^*)$ for $Y_{ij}$, the number of shells found at each site. We then refit the model to obtain 1000 bootstrapped estimates of $\beta_0^*$, $\beta_1^*$, and $\sigma^2$. Finally, we compute the standard errors of each estimate, as well as the confidence intervals.

The table below summarizes the output obtained from the function after using the gopher tortoise dataset.

```{r}



```

We also consider how we can use the bootstrap to perform hypothesis tests. We wish to test the null hypothesis that there is no effect of prevalence on the number of shells found at each site:

$$
H_0: \beta_1 = 0 \text{ versus } H_1: \beta_1 \neq 0
$$ Since the p-value is the probability that we observe a value of the test statistic as extreme or more extreme than what we observed given that the null hypothesis is true, we need to simulate form the sampling distribution of $\beta_1$ given that the null hypothesis is true. To do this, we repeat the bootstrap process above but use the linear predictor under the null hypothesis, which is:

$$
\eta_{ij} = \beta_0 + log(x_{i2}) + z_i
$$

The function titled Hypothesis_Test within this package computes and returns the p-value after bootstrapping. The model is fit using the run_model function and a t-value for $\hat{\beta_1}$, the coefficient estimate for the seroprevalence parameter, is obtained. The function then generates bootstrapped samples for the random effects, and computes the value of $\eta_{ij}$ as seen above, allowing for the value of $\mu_{ij}$ to be obtained as well. The values of $Y_{ij}$ are then computed and the model is refit. The function then finds the bootstrapped test statistic values and computes the p-value, which is then returned.

Below, we implement the Hypothesis_Test function using the tortoise data.

```{r}

p_value <- Hypothesis_Test(tortoise_clean)
p_value

```

The p-value computed is 0. A p-value won't be exactly 0 since it is the area under the t-distribution curve, so we can assume that the p-value obtained is very small. This makes sense since in the original fit of the model, the t-statistic obtained for the parameter estimate for the prevalence is close to 5, which is very large. Since we have a small p-value, we can reject the null hypothesis and say that the seroprevalence of upper respiratory tract infections in Gopher Tortoises does have an effect on the number of shells found after accounting for the area of each site.
